{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "input_file = 'Y_train.csv'\n",
    "with open(input_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "title = data[0]\n",
    "\n",
    "rows = data[1:]\n",
    "\n",
    "for i in range(24):\n",
    "    extracted_rows = [rows[j] for j in range(len(rows)) if (j - i) % 24 == 0]\n",
    "    \n",
    "    output_file = f'./generated_data/output_{i+1}.csv'\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(title)\n",
    "        writer.writerows(extracted_rows)\n",
    "\n",
    "    with open(output_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    \n",
    "    title_row = data[0]\n",
    "    rows_data = data[1:]\n",
    "    \n",
    "    for row in rows_data:\n",
    "        original_value = float(row[0])\n",
    "        for j in range(1, 2):\n",
    "            random_factor = random.uniform(-0.15, 0.15)\n",
    "            new_value = original_value * (1 + random_factor)\n",
    "            row.append(f\"{new_value:.2f}\")\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(title_row + ['Change1'])\n",
    "        writer.writerows(rows_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "mpc_bus = [\n",
    "    [1, 51], [2, 20], [3, 39], [4, 39], [5, 0], [6, 52], [7, 19], [8, 28], [9, 0], [10, 0],\n",
    "    [11, 70], [12, 47], [13, 34], [14, 14], [15, 90], [16, 25], [17, 11], [18, 60], [19, 45], [20, 18],\n",
    "    [21, 14], [22, 10], [23, 7], [24, 13], [25, 0], [26, 0], [27, 71], [28, 17], [29, 24], [30, 0],\n",
    "    [31, 43], [32, 59], [33, 23], [34, 59], [35, 33], [36, 31], [37, 0], [38, 0], [39, 27], [40, 66],\n",
    "    [41, 37], [42, 96], [43, 18], [44, 16], [45, 53], [46, 28], [47, 34], [48, 20], [49, 87], [50, 17],\n",
    "    [51, 17], [52, 18], [53, 23], [54, 113], [55, 63], [56, 84], [57, 12], [58, 12], [59, 277], [60, 78],\n",
    "    [61, 0], [62, 77], [63, 0], [64, 0], [65, 0], [66, 39], [67, 28], [68, 0], [69, 0], [70, 66],\n",
    "    [71, 0], [72, 12], [73, 6], [74, 68], [75, 47], [76, 68], [77, 61], [78, 71], [79, 39], [80, 130],\n",
    "    [81, 0], [82, 54], [83, 20], [84, 11], [85, 24], [86, 21], [87, 0], [88, 48], [89, 0], [90, 163],\n",
    "    [91, 10], [92, 65], [93, 12], [94, 30], [95, 42], [96, 38], [97, 15], [98, 34], [99, 42], [100, 37],\n",
    "    [101, 22], [102, 5], [103, 23], [104, 38], [105, 31], [106, 43], [107, 50], [108, 2], [109, 8], [110, 39],\n",
    "    [111, 0], [112, 68], [113, 6], [114, 8], [115, 22], [116, 184], [117, 20], [118, 33]\n",
    "]\n",
    "\n",
    "ratio_bus = np.zeros(118)\n",
    "for i in range(118):\n",
    "    ratio_bus[i] = mpc_bus[i][1] / sum(mpc_bus[j][1] for j in range(118))\n",
    "\n",
    "parent_folder = './hour'\n",
    "if not os.path.exists(parent_folder):\n",
    "    os.makedirs(parent_folder)\n",
    "\n",
    "for file_num in range(1, 25):\n",
    "    input_file = f'./generated_data/output_{file_num}.csv'\n",
    "    with open(input_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "\n",
    "    title = data[0]\n",
    "    rows = data[1:]\n",
    "\n",
    "    folder_path = f'{parent_folder}/{file_num}'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    allocated_data = []\n",
    "    for row in rows:\n",
    "        total_value = float(row[0])  \n",
    "        allocated_row = [total_value * ratio_bus[i] for i in range(118)]\n",
    "        allocated_data.append(allocated_row)\n",
    "\n",
    "    output_file = f'{folder_path}/allocated_output_perfect.csv'\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Node_' + str(i+1) for i in range(118)])  \n",
    "        writer.writerows(allocated_data)\n",
    "\n",
    "    for col in range(1, 2):\n",
    "        allocated_data = []\n",
    "        for row in rows:\n",
    "            total_value = float(row[col])  \n",
    "            allocated_row = [total_value * ratio_bus[i] for i in range(118)]\n",
    "            allocated_data.append(allocated_row)\n",
    "\n",
    "        output_file = f'{folder_path}/allocated_output_change{col}.csv'\n",
    "        with open(output_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Node_' + str(i+1) for i in range(118)]) \n",
    "            writer.writerows(allocated_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import os\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def calculate_optimization_cost_two_stage(P_l_predict, Y_real, topo, unit, reserve_up=150, reserve_down=150, c=9000, c_s=1750):\n",
    "\n",
    "    P_l_predict = np.array(P_l_predict).T    \n",
    "    Y_real = np.array(Y_real).T\n",
    "    \n",
    "    nodes = topo.shape[0]\n",
    "    \n",
    "    model_DA = gp.Model()\n",
    "    \n",
    "    P_c = model_DA.addVars(nodes,  lb=0, name='P_c')       \n",
    "    R_U = model_DA.addVars(nodes,  lb=0, name='R_U')       \n",
    "    R_D = model_DA.addVars(nodes,  lb=0, name='R_D')       \n",
    "    delta_DA = model_DA.addVars(nodes,  lb=-180, ub=180, name='delta_DA') \n",
    "    \n",
    "    obj_DA = gp.quicksum(\n",
    "        R_U[i]*unit.iloc[i,5] + \n",
    "        R_D[i]*unit.iloc[i,6] + \n",
    "        P_c[i]*unit.iloc[i,2] \n",
    "        for i in range(nodes) \n",
    "    )\n",
    "    model_DA.setObjective(obj_DA, GRB.MINIMIZE)\n",
    "    \n",
    "\n",
    "    model_DA.addConstr(gp.quicksum(R_U[i] for i in range(nodes)) == reserve_up)\n",
    "    model_DA.addConstr(gp.quicksum(R_D[i] for i in range(nodes)) == reserve_down)\n",
    "    for i in range(nodes):\n",
    "        model_DA.addConstr(R_U[i] <= unit.iloc[i,3])  \n",
    "        model_DA.addConstr(R_D[i] <= unit.iloc[i,4])  \n",
    "\n",
    "    for t in range(nodes):\n",
    "        model_DA.addConstr(\n",
    "            P_c[t] - P_l_predict[t] - \n",
    "            gp.quicksum(topo.iloc[t,j]*(delta_DA[t]-delta_DA[j]) for j in range(nodes)) == 0\n",
    "        )\n",
    "    model_DA.addConstr(delta_DA[0] == 0)  \n",
    "       \n",
    "    for i in range(nodes):\n",
    "        model_DA.addConstr(P_c[i] <= unit.iloc[i,1] - R_U[i])  \n",
    "        model_DA.addConstr(P_c[i] >= R_D[i])                   \n",
    "        \n",
    "    for i in range(nodes):\n",
    "        for j in range(nodes):\n",
    "            if i != j and topo.iloc[i,j] < -0.01:\n",
    "                model_DA.addConstr(topo.iloc[i,j] * (delta_DA[i] - delta_DA[j]) <= 175)\n",
    "                model_DA.addConstr(topo.iloc[i,j] * (delta_DA[i] - delta_DA[j]) >= -175)\n",
    "    \n",
    "    model_DA.optimize()\n",
    "    \n",
    "    model_RT = gp.Model()\n",
    "    \n",
    "    \n",
    "    r_U = model_RT.addVars(nodes,  lb=0, name='r_U')       \n",
    "    r_D = model_RT.addVars(nodes,  lb=0, name='r_D')       \n",
    "    P_lsh = model_RT.addVars(nodes,  lb=0, name='P_lsh')  \n",
    "    delta_RT = model_RT.addVars(nodes,  lb=-180, ub=180, name='delta_RT') \n",
    "    s = model_RT.addVars(nodes,  lb=0, name='s')           \n",
    "    \n",
    "    \n",
    "    obj_RT = gp.quicksum(\n",
    "        (r_U[i]-r_D[i])*unit.iloc[i,2] \n",
    "        for i in range(nodes) \n",
    "    )\n",
    "    obj_RT += gp.quicksum(P_lsh[i]*c for i in range(nodes) )\n",
    "    obj_RT += gp.quicksum(s[i]*c_s for i in range(nodes) )\n",
    "    model_RT.setObjective(obj_RT, GRB.MINIMIZE)\n",
    "    \n",
    "    \n",
    "    for t in range(nodes):\n",
    "        model_RT.addConstr(\n",
    "            r_U[t] - r_D[t] - s[t] - Y_real[t] + P_l_predict[t] + P_lsh[t] - \n",
    "            gp.quicksum(\n",
    "                topo.iloc[t,j]*(delta_RT[t]-delta_RT[j]) - \n",
    "                topo.iloc[t,j]*(delta_DA[t].X-delta_DA[j].X) \n",
    "                for j in range(nodes)\n",
    "            ) == 0\n",
    "        )\n",
    "        \n",
    "    for i in range(nodes):\n",
    "        model_RT.addConstr(r_U[i] <= R_U[i].X) \n",
    "        model_RT.addConstr(r_D[i] <= R_D[i].X)  \n",
    "    model_RT.addConstr(delta_RT[0] == 0)  \n",
    "        \n",
    "    for i in range(nodes):\n",
    "        for j in range(nodes):\n",
    "            if i != j and topo.iloc[i,j] < -0.01:\n",
    "                model_RT.addConstr(topo.iloc[i,j] * (delta_RT[i] - delta_RT[j]) <= 175)\n",
    "                model_RT.addConstr(topo.iloc[i,j] * (delta_RT[i] - delta_RT[j]) >= -175)\n",
    "    \n",
    "    model_RT.optimize()\n",
    "    \n",
    "    \n",
    "    total_cost = model_DA.ObjVal + model_RT.ObjVal\n",
    "    \n",
    "    \n",
    "    \n",
    "    model_DA.dispose()\n",
    "    model_RT.dispose()\n",
    "    \n",
    "    return total_cost\n",
    "# System parameters (topology data and generator unit data)\n",
    "topo = pd.read_excel('118nodes_system.xlsx', sheet_name='topology', index_col=None, header=None) \n",
    "unit = pd.read_excel('118nodes_system.xlsx', sheet_name='unit')\n",
    "\n",
    "hour_folder = './hour'\n",
    "for hour in range(1, 25):\n",
    "    hour_dir = os.path.join(hour_folder, str(hour))\n",
    "    if not os.path.exists(hour_dir):\n",
    "        continue\n",
    "    \n",
    "\n",
    "    perfect_file = os.path.join(hour_dir, 'allocated_output_perfect.csv')\n",
    "    if not os.path.exists(perfect_file):\n",
    "        continue\n",
    "    \n",
    "\n",
    "    with open(perfect_file, 'r') as f_perfect:\n",
    "        reader_perfect = csv.reader(f_perfect)\n",
    "        next(reader_perfect)  \n",
    "        perfect_data = [list(map(float, row)) for row in reader_perfect]\n",
    "    \n",
    "    \n",
    "    perfect_costs = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        \n",
    "        perfect_costs = list(executor.map(lambda x: calculate_optimization_cost_two_stage(x, x, topo, unit), perfect_data))\n",
    "    \n",
    "    \n",
    "    perfect_cost_file = os.path.join(hour_dir, 'perfect_costs.csv')\n",
    "    with open(perfect_cost_file, 'w', newline='') as f_perfect_cost:\n",
    "        writer = csv.writer(f_perfect_cost)\n",
    "        writer.writerow(['Perfect_Cost'])\n",
    "        writer.writerows([[cost] for cost in perfect_costs])\n",
    "    \n",
    "    \n",
    "    cost_differences = []  \n",
    "    for file_prefix in ['allocated_output_change1']:\n",
    "        input_file = os.path.join(hour_dir, f'{file_prefix}.csv')\n",
    "        if not os.path.exists(input_file):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        with open(input_file, 'r') as f_in:\n",
    "            reader = csv.reader(f_in)\n",
    "            next(reader)  \n",
    "            data = [list(map(float, row)) for row in reader]\n",
    "        \n",
    "        \n",
    "        total_costs = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            total_costs = list(executor.map(lambda x: calculate_optimization_cost_two_stage(x[0], x[1], topo, unit), zip(data, perfect_data)))\n",
    "        \n",
    "        cost_diff = [total_costs[i] - perfect_costs[i] for i in range(len(total_costs))]\n",
    "        cost_differences.append(cost_diff)\n",
    "    \n",
    "    if cost_differences:\n",
    "        output_file = os.path.join(hour_dir, 'cost_differences.csv')\n",
    "        with open(output_file, 'w', newline='') as f_out:\n",
    "            writer = csv.writer(f_out)\n",
    "            writer.writerow(['Change1'])\n",
    "            writer.writerows(zip(*cost_differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ./generated_data\\output_1.csv complete, save to load_variation\\load_variation_1.csv\n",
      " ./generated_data\\output_2.csv complete, save to load_variation\\load_variation_2.csv\n",
      " ./generated_data\\output_3.csv complete, save to load_variation\\load_variation_3.csv\n",
      " ./generated_data\\output_4.csv complete, save to load_variation\\load_variation_4.csv\n",
      " ./generated_data\\output_5.csv complete, save to load_variation\\load_variation_5.csv\n",
      " ./generated_data\\output_6.csv complete, save to load_variation\\load_variation_6.csv\n",
      " ./generated_data\\output_7.csv complete, save to load_variation\\load_variation_7.csv\n",
      " ./generated_data\\output_8.csv complete, save to load_variation\\load_variation_8.csv\n",
      " ./generated_data\\output_9.csv complete, save to load_variation\\load_variation_9.csv\n",
      " ./generated_data\\output_10.csv complete, save to load_variation\\load_variation_10.csv\n",
      " ./generated_data\\output_11.csv complete, save to load_variation\\load_variation_11.csv\n",
      " ./generated_data\\output_12.csv complete, save to load_variation\\load_variation_12.csv\n",
      " ./generated_data\\output_13.csv complete, save to load_variation\\load_variation_13.csv\n",
      " ./generated_data\\output_14.csv complete, save to load_variation\\load_variation_14.csv\n",
      " ./generated_data\\output_15.csv complete, save to load_variation\\load_variation_15.csv\n",
      " ./generated_data\\output_16.csv complete, save to load_variation\\load_variation_16.csv\n",
      " ./generated_data\\output_17.csv complete, save to load_variation\\load_variation_17.csv\n",
      " ./generated_data\\output_18.csv complete, save to load_variation\\load_variation_18.csv\n",
      " ./generated_data\\output_19.csv complete, save to load_variation\\load_variation_19.csv\n",
      " ./generated_data\\output_20.csv complete, save to load_variation\\load_variation_20.csv\n",
      " ./generated_data\\output_21.csv complete, save to load_variation\\load_variation_21.csv\n",
      " ./generated_data\\output_22.csv complete, save to load_variation\\load_variation_22.csv\n",
      " ./generated_data\\output_23.csv complete, save to load_variation\\load_variation_23.csv\n",
      " ./generated_data\\output_24.csv complete, save to load_variation\\load_variation_24.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_folder = './generated_data'  \n",
    "output_folder = 'load_variation'  \n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for i in range(1, 25):\n",
    "    input_file = os.path.join(input_folder, f'output_{i}.csv')\n",
    "    output_file = os.path.join(output_folder, f'load_variation_{i}.csv')\n",
    "    \n",
    "    if os.path.exists(input_file):\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        \n",
    "        required_columns = ['load (MW)', 'Change1']\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            \n",
    "            load_variation = df[['Change1']].sub(df['load (MW)'], axis=0)\n",
    "            \n",
    "            \n",
    "            load_variation.to_csv(output_file, index=False)\n",
    "            print(f\" {input_file} complete, save to {output_file}\")\n",
    "        else:\n",
    "            print(f\" {input_file} skip\")\n",
    "    else:\n",
    "        print(f\" {input_file} not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def split_and_save_data(X_train_file, Y_train_file, output_dir):\n",
    "    \n",
    "    X_train = pd.read_csv(X_train_file)\n",
    "    Y_train = pd.read_csv(Y_train_file)\n",
    "\n",
    "    \n",
    "    if len(X_train) != len(Y_train):\n",
    "        raise ValueError(\"error\")\n",
    "\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "    for i in range(24):\n",
    "        \n",
    "        extracted_X = X_train[(X_train.index - i) % 24 == 0]\n",
    "        extracted_Y = Y_train[(Y_train.index - i) % 24 == 0]\n",
    "\n",
    "        \n",
    "        if len(extracted_X) != len(extracted_Y):\n",
    "            raise ValueError(f\"hour{i}error\")\n",
    "\n",
    "        \n",
    "        X_output_file = os.path.join(output_dir, f'X_train_hour_{i + 1}.csv')\n",
    "        Y_output_file = os.path.join(output_dir, f'Y_train_hour_{i + 1}.csv')\n",
    "        extracted_X.to_csv(X_output_file, index=False)\n",
    "        extracted_Y.to_csv(Y_output_file, index=False)\n",
    "\n",
    "X_train_file = './X_train.csv'  \n",
    "Y_train_file = './Y_train.csv'  \n",
    "output_dir = './hourly_data'    \n",
    "\n",
    "\n",
    "split_and_save_data(X_train_file, Y_train_file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_test_data_by_hour(X_test_file, Y_test_file, output_folder, start_hour=7):\n",
    "    \n",
    "    X_test = pd.read_csv(X_test_file)\n",
    "    Y_test = pd.read_csv(Y_test_file)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    \n",
    "    for hour in range(24):\n",
    "        \n",
    "        actual_hour = (start_hour - 1 + hour) % 24 + 1\n",
    "\n",
    "        \n",
    "        extracted_X = X_test.iloc[hour::24, :]\n",
    "        extracted_Y = Y_test.iloc[hour::24, :]\n",
    "\n",
    "        \n",
    "        extracted_X.to_csv(f'{output_folder}/X_test_hour_{actual_hour}.csv', index=False)\n",
    "        extracted_Y.to_csv(f'{output_folder}/Y_test_hour_{actual_hour}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    X_test_file = 'X_test.csv'\n",
    "    Y_test_file = 'Y_test.csv'\n",
    "\n",
    "    output_folder = './test_split'\n",
    "\n",
    "    split_test_data_by_hour(X_test_file, Y_test_file, output_folder, start_hour=7)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete: ./hour\\1\n",
      "complete: ./hour\\2\n",
      "complete: ./hour\\3\n",
      "complete: ./hour\\4\n",
      "complete: ./hour\\5\n",
      "complete: ./hour\\6\n",
      "complete: ./hour\\7\n",
      "complete: ./hour\\8\n",
      "complete: ./hour\\9\n",
      "complete: ./hour\\10\n",
      "complete: ./hour\\11\n",
      "complete: ./hour\\12\n",
      "complete: ./hour\\13\n",
      "complete: ./hour\\14\n",
      "complete: ./hour\\15\n",
      "complete: ./hour\\16\n",
      "complete: ./hour\\17\n",
      "complete: ./hour\\18\n",
      "complete: ./hour\\19\n",
      "complete: ./hour\\20\n",
      "complete: ./hour\\21\n",
      "complete: ./hour\\22\n",
      "complete: ./hour\\23\n",
      "complete: ./hour\\24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_dir = './hour'\n",
    "\n",
    "\n",
    "for folder_num in range(1, 25):\n",
    "    folder_path = os.path.join(base_dir, str(folder_num))\n",
    "    \n",
    "    cost_diff_path = os.path.join(folder_path, 'cost_differences.csv')\n",
    "    cost_diff_df = pd.read_csv(cost_diff_path)\n",
    "    \n",
    "    perfect_cost_path = os.path.join(folder_path, 'perfect_costs.csv')\n",
    "    perfect_cost_df = pd.read_csv(perfect_cost_path)\n",
    "    \n",
    "    result_df = cost_diff_df.div(perfect_cost_df['Perfect_Cost'], axis=0)\n",
    "    \n",
    "    result_path = os.path.join(folder_path, 'divided_costs.csv')\n",
    "    result_df.to_csv(result_path, index=False)\n",
    "    \n",
    "    print(f\"complete: {folder_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "load_variation_dir = './load_variation'\n",
    "hourly_data_dir = './hourly_data'\n",
    "\n",
    "\n",
    "for i in range(1, 25):\n",
    "    \n",
    "    load_variation_file = os.path.join(load_variation_dir, f'load_variation_{i}.csv')\n",
    "    y_train_file = os.path.join(hourly_data_dir, f'Y_train_hour_{i}.csv')\n",
    "    \n",
    "    \n",
    "    load_variation_df = pd.read_csv(load_variation_file)\n",
    "    \n",
    "    \n",
    "    y_train_df = pd.read_csv(y_train_file)\n",
    "    y_train_column = y_train_df.iloc[:, 0]  \n",
    "    \n",
    "    \n",
    "    result_df = load_variation_df.div(y_train_column, axis=0)\n",
    "    \n",
    "    \n",
    "    result_file = os.path.join(load_variation_dir, f'load_variation_divided_{i}.csv')\n",
    "    result_df.to_csv(result_file, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNL",
   "language": "python",
   "name": "nnl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
